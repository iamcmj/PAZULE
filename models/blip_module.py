# /models/blip_module.py

import os
import json
import torch
from PIL import Image
from transformers import BlipProcessor, BlipForQuestionAnswering


# --- ë””ë°”ì´ìŠ¤ ì„¤ì • ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"BLIP Module: Using device '{DEVICE}'")

# --- ëª¨ë¸ ì´ë¦„ ---
MODEL_NAME = "Salesforce/blip-vqa-base"

# --- ëœë“œë§ˆí¬ë³„ Q&A JSON íŒŒì¼ ê²½ë¡œ ---
MODULE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(MODULE_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
LANDMARK_QA_FILE = os.path.join(DATA_DIR, "landmark_qa.json")

# --- ë¯¸ì…˜ ì„±ê³µ ê¸°ì¤€ (75%) ---
SUCCESS_THRESHOLD = 0.75


# =====================================
# ëª¨ë¸ ë° ë°ì´í„° ì „ì—­ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
# =====================================


def load_model():
    """BLIP VQA ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"Loading BLIP VQA model '{MODEL_NAME}'...")
    try:
        processor = BlipProcessor.from_pretrained(MODEL_NAME)
        model = BlipForQuestionAnswering.from_pretrained(MODEL_NAME).to(DEVICE)
        print("BLIP VQA model loaded successfully.")
        return processor, model
    except Exception as e:
        print(f"Error loading BLIP model: {e}")
        return None, None


def load_landmark_qa():
    """ëœë“œë§ˆí¬ë³„ Q&A ë°ì´í„°ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(LANDMARK_QA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"Landmark Q&A data loaded from '{LANDMARK_QA_FILE}'.")
            return data
    except FileNotFoundError:
        print(f"Error: Landmark Q&A file not found at '{LANDMARK_QA_FILE}'.")
        return {}
    except json.JSONDecodeError:
        print(f"Error: Failed to decode JSON from '{LANDMARK_QA_FILE}'.")
        return {}


# --- ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ ---
processor, model = load_model()
landmark_qa_data = load_landmark_qa()


# =====================================
# ë©”ì¸ í•¨ìˆ˜
# =====================================


def check_with_blip(user_image_path, landmark_name):
    """
    BLIP VQAë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì ì´ë¯¸ì§€ê°€ í•´ë‹¹ ëœë“œë§ˆí¬ê°€ ë§ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    JSONì— ì •ì˜ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  'yes' ë‹µë³€ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        user_image_path (str): ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        landmark_name (str): ì˜¤ëŠ˜ì˜ ì •ë‹µ ëœë“œë§ˆí¬ ì´ë¦„ (ì˜ˆ: "í”¼ë…¸í‚¤ì˜¤")

    Returns:
        tuple: (is_success, hint_payload)
               is_success (bool): ë¯¸ì…˜ ì„±ê³µ ì—¬ë¶€ (True/False)
               hint_payload (list): 'no'ë¡œ ë‹µë³€ëœ ì§ˆë¬¸ ëª©ë¡ (LLM íŒíŠ¸ ìƒì„±ìš©)
    """

    # --- 0. ëª¨ë¸ ë¡œë“œ í™•ì¸ ---
    if not processor or not model:
        print("Error: BLIP model is not loaded. Aborting mission.")
        return False, []

    # --- 1. ëœë“œë§ˆí¬ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ---
    question_list = landmark_qa_data.get(landmark_name)

    if not question_list:
        print(f"Warning: No Q&A data found for landmark '{landmark_name}'.")
        return False, []

    total_questions = len(question_list)
    if total_questions == 0:
        print(f"Warning: Empty Q&A list for landmark '{landmark_name}'.")
        return False, []

    # --- 2. ì´ë¯¸ì§€ ë¡œë“œ ---
    try:
        raw_image = Image.open(user_image_path).convert("RGB")
    except FileNotFoundError:
        print(f"Error: User image not found at '{user_image_path}'.")
        return False, []
    except Exception as e:
        print(f"Error loading image '{user_image_path}': {e}")
        return False, []

    # --- 3. VQA ì‹¤í–‰ ë° 'yes' ì¹´ìš´íŠ¸ ---
    yes_count = 0
    no_questions_list = []  # 'no' ë‹µë³€ëœ ì§ˆë¬¸ ì €ì¥ìš©

    try:
        pixel_values = processor(images=raw_image, return_tensors="pt").pixel_values.to(
            DEVICE
        )
    except Exception as e:
        print(f"Error processing image with BLIP: {e}")
        return False, []

    print(
        f"Running VQA for landmark '{landmark_name}' ({total_questions} questions)..."
    )

    for question in question_list:
        try:
            inputs = processor(text=question, return_tensors="pt").to(DEVICE)

            out = model.generate(
                pixel_values=pixel_values,
                input_ids=inputs.input_ids,
                attention_mask=inputs.attention_mask,
                max_new_tokens=10,
            )

            model_answer = (
                processor.decode(out[0], skip_special_tokens=True).strip().lower()
            )

            # [ìˆ˜ì •] ëª¨ë¸ì˜ ë‹µë³€ì´ 'yes'ì¸ì§€ í™•ì¸
            if model_answer == "yes":
                yes_count += 1
            else:
                # 'yes'ê°€ ì•„ë‹ˆë©´ (ì¦‰, 'no' ë˜ëŠ” ë‹¤ë¥¸ ë‹µë³€) íŒíŠ¸ ëª©ë¡ì— ì§ˆë¬¸ ì¶”ê°€
                no_questions_list.append(question)

        except Exception as e:
            print(f"Error during VQA processing for question '{question}': {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ 'no'ë¡œ ê°„ì£¼í•˜ê³  ëª©ë¡ì— ì¶”ê°€
            no_questions_list.append(question)

    # --- 4. ìµœì¢… ì„±ê³µ ì—¬ë¶€ íŒë³„ ---
    match_ratio = yes_count / total_questions
    is_success = match_ratio >= SUCCESS_THRESHOLD

    print(
        f"VQA Result: {yes_count}/{total_questions} 'yes' answers ({match_ratio:.2%}). Success: {is_success}"
    )

    if is_success:
        return True, no_questions_list
    else:
        # [ìˆ˜ì •] ì‹¤íŒ¨ ì‹œ 'no'ë¡œ ë‹µë³€ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        return False, no_questions_list


# =====================================
# âš ï¸ ì£¼ì˜: ì•„ë˜ ì½”ë“œëŠ” í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤
# =====================================
# ì´ ë¸”ë¡ì€ ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤ (python blip_module.py)
# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importí•  ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì„œë²„ ì¶”ë¡ ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
if __name__ == "__main__":

    # --- 1. í…ŒìŠ¤íŠ¸ ì„¤ì • ---

    # [ì£¼ì˜!] main.pyì—ì„œ './metadata/test_image/test1.HEIC'ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    # .HEIC í¬ë§·ì€ 'pip install pillow-heif'ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ PILì´ ì—´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    #
    # ë§Œì•½ pillow-heifë¥¼ ì„¤ì¹˜í•˜ì§€ ì•Šì•˜ë‹¤ë©´,
    # ì´ íŒŒì¼ ì´ë¦„ì„ í…ŒìŠ¤íŠ¸í•˜ë ¤ëŠ” .jpg ë˜ëŠ” .png íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.
    test_image_name = "test3.jpg"

    # 'data/landmark_qa.json'ì— ì •ì˜ëœ í…ŒìŠ¤íŠ¸í•˜ë ¤ëŠ” ëœë“œë§ˆí¬ ì´ë¦„
    test_landmark = "í”¼ë…¸í‚¤ì˜¤"

    # --- 2. í…ŒìŠ¤íŠ¸ ê²½ë¡œ ì„¤ì • ---
    # (ê²½ë¡œëŠ” ì´ë¯¸ íŒŒì¼ ìƒë‹¨ì— ì •ì˜ëœ PROJECT_ROOTë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤)
    test_image_path = os.path.join(
        PROJECT_ROOT, "metadata", "test_image", test_image_name
    )

    print("=" * 30)
    print("  BLIP Module Standalone Test  ")
    print("=" * 30)

    # --- 3. ì‹¤í–‰ ì „ ê¸°ë³¸ í™•ì¸ ---
    if not processor or not model:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: BLIP ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    elif not landmark_qa_data:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {LANDMARK_QA_FILE} íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    elif not landmark_qa_data.get(test_landmark):
        print(
            f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: '{LANDMARK_QA_FILE}'ì— '{test_landmark}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        )
    elif not os.path.exists(test_image_path):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   (ê²½ë¡œ: {test_image_path})")
    else:
        # --- 4. ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ---
        print(f"â–¶ï¸ Test Image: {test_image_path}")
        print(f"â–¶ï¸ Test Landmark: {test_landmark}")
        print("Running check_with_blip...")

        try:
            is_success, hint_payload = check_with_blip(test_image_path, test_landmark)

            print("\n--- ğŸ’¡ Test Result ---")
            print(f"Success: {is_success}")
            print(hint_payload)
            if not is_success:
                print("Hint Payload ('no' or error questions):")
                for q in hint_payload:
                    print(f"  - {q}")
            print("-----------------------")

        except Exception as e:
            print(f"\n--- âŒ Test Failed with Runtime Exception ---")
            print(f"Error: {e}")
            if "cannot read HEIC file" in str(e):
                print("\n[ì•Œë¦¼] .HEIC íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(
                    "í„°ë¯¸ë„ì—ì„œ 'pip install pillow-heif'ë¥¼ ì‹¤í–‰í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                )
            print("---------------------------------------------")
