# /models/blip_module.py

import os
import json
import torch
from PIL import Image
from transformers import BlipProcessor, BlipForQuestionAnswering
from tqdm import tqdm


# --- ë””ë°”ì´ìŠ¤ ì„¤ì • ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"BLIP Module: Using device '{DEVICE}'")

# --- ëª¨ë¸ ì´ë¦„ ---
MODEL_NAME = "Salesforce/blip-vqa-base"

# --- ëœë“œë§ˆí¬ë³„ Q&A JSON íŒŒì¼ ê²½ë¡œ ---
MODULE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(MODULE_DIR)
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
LANDMARK_QA_FILE = os.path.join(DATA_DIR, "landmark_qa_labeled.json")

# --- ë¯¸ì…˜ ì„±ê³µ ê¸°ì¤€ (75%) ---
SUCCESS_THRESHOLD = 0.75


# =====================================
# ëª¨ë¸ ë° ë°ì´í„° ì „ì—­ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
# =====================================


def load_model():
    """BLIP VQA ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print(f"Loading BLIP VQA model '{MODEL_NAME}'...")
    try:
        processor = BlipProcessor.from_pretrained(MODEL_NAME)
        model = BlipForQuestionAnswering.from_pretrained(MODEL_NAME).to(DEVICE)
        print("BLIP VQA model loaded successfully.")
        return processor, model
    except Exception as e:
        print(f"Error loading BLIP model: {e}")
        return None, None


def load_landmark_qa():
    """ëœë“œë§ˆí¬ë³„ Q&A ë°ì´í„°ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤."""
    # ë¨¼ì € landmark_qa_labeled.json ì‹œë„, ì—†ìœ¼ë©´ landmark_qa.json ì‚¬ìš©
    fallback_file = os.path.join(DATA_DIR, "landmark_qa.json")
    
    try:
        with open(LANDMARK_QA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"Landmark Q&A data loaded from '{LANDMARK_QA_FILE}'.")
            return data
    except FileNotFoundError:
        # fallback íŒŒì¼ ì‹œë„
        if os.path.exists(fallback_file):
            try:
                with open(fallback_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    print(f"Landmark Q&A data loaded from fallback file '{fallback_file}'.")
                    return data
            except Exception as e:
                print(f"Error: Failed to load fallback file '{fallback_file}': {e}")
        else:
            print(f"Error: Landmark Q&A file not found at '{LANDMARK_QA_FILE}' or '{fallback_file}'.")
        return {}
    except json.JSONDecodeError:
        print(f"Error: Failed to decode JSON from '{LANDMARK_QA_FILE}'.")
        return {}


# --- ëª¨ë¸ê³¼ ë°ì´í„° ë¡œë“œ ---
processor, model = load_model()
landmark_qa_data = load_landmark_qa()


# =====================================
# ë©”ì¸ í•¨ìˆ˜
# =====================================


def check_with_blip(user_image_path, landmark_name):
    """
    BLIP VQAë¥¼ ì‚¬ìš©í•´ ì‚¬ìš©ì ì´ë¯¸ì§€ê°€ í•´ë‹¹ ëœë“œë§ˆí¬ê°€ ë§ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    JSONì— ì •ì˜ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  ë°”ë¥¸ ë‹µë³€ì˜ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        user_image_path (str): ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        landmark_name (str): ì˜¤ëŠ˜ì˜ ì •ë‹µ ëœë“œë§ˆí¬ ì´ë¦„ (ì˜ˆ: "í”¼ë…¸í‚¤ì˜¤")

    Returns:
        tuple: (is_success, hint_payload)
               is_success (bool): ë¯¸ì…˜ ì„±ê³µ ì—¬ë¶€ (True/False)
               hint_payload (list): í‹€ë¦¬ê²Œ ë‹µë³€í•œ ì§ˆë¬¸ ëª©ë¡ (LLM íŒíŠ¸ ìƒì„±ìš©)
    """

    # --- 0. ëª¨ë¸ ë¡œë“œ í™•ì¸ ---
    if not processor or not model:
        print("Error: BLIP model is not loaded. Aborting mission.")
        return False, []

    # --- 1. ëœë“œë§ˆí¬ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ---
    question_list = landmark_qa_data.get(landmark_name)

    if not question_list:
        print(f"Warning: No Q&A data found for landmark '{landmark_name}'.")
        return False, []

    total_questions = len(question_list)
    if total_questions == 0:
        print(f"Warning: Empty Q&A list for landmark '{landmark_name}'.")
        return False, []

    # --- 2. ì´ë¯¸ì§€ ë¡œë“œ ---
    try:
        raw_image = Image.open(user_image_path).convert("RGB")
    except FileNotFoundError:
        print(f"Error: User image not found at '{user_image_path}'.")
        return False, []
    except Exception as e:
        print(f"Error loading image '{user_image_path}': {e}")
        return False, []

    # --- 3. VQA ì‹¤í–‰ ë° ì •í™•ë„ ê³„ì‚° ---
    correct_count = 0
    incorrect_questions_list = []  # ì˜¤ë‹µ ëª©ë¡ ì €ì¥ìš©

    try:
        pixel_values = processor(images=raw_image, return_tensors="pt").pixel_values.to(
            DEVICE
        )
    except Exception as e:
        print(f"Error processing image with BLIP: {e}")
        return False, []

    print(
        f"Running VQA for landmark '{landmark_name}' ({total_questions} questions)..."
    )

    for item in tqdm(question_list, desc=f"Running BLIP VQA for {landmark_name}", unit="question"):
        question = item[0]
        expected_answer = item[1]
        
        try:
            inputs = processor(text=question, return_tensors="pt").to(DEVICE)

            out = model.generate(
                pixel_values=pixel_values,
                input_ids=inputs.input_ids,
                attention_mask=inputs.attention_mask,
                max_new_tokens=10,
            )
            
            model_answer = processor.decode(out[0], skip_special_tokens=True).strip().lower()
            
            if model_answer == expected_answer:
                correct_count += 1
            else:
                # ë‹µë³€ì´ í‹€ë ¸ì„ ê²½ìš°, ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜ íŒíŠ¸ ëª©ë¡ì— ì¶”ê°€
                incorrect_questions_list.append({
                    "question": question,
                    "model_answer": model_answer,
                    "expected_answer": expected_answer
                })
                
        except Exception as e:
            print(f"Error during VQA processing for question '{question}': {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì˜¤ë‹µìœ¼ë¡œ ê°„ì£¼í•˜ê³  ëª©ë¡ì— ì¶”ê°€
            incorrect_questions_list.append({
                "question": question,
                "model_answer": "error",
                "expected_answer": expected_answer
            })

    # --- 4. ìµœì¢… ì„±ê³µ ì—¬ë¶€ íŒë³„ ---
    accuracy = correct_count / total_questions
    is_success = accuracy >= SUCCESS_THRESHOLD

    print(f"VQA Result: {correct_count}/{total_questions} correct answers ({accuracy:.2%}). Success: {is_success}")

    if is_success:
        return True, [] # ì„±ê³µ ì‹œì—ëŠ” ë¹ˆ íŒíŠ¸ í˜ì´ë¡œë“œ ë°˜í™˜
    else:
        # ì‹¤íŒ¨ ì‹œ ì˜¤ë‹µ ëª©ë¡ì„ íŒíŠ¸ í˜ì´ë¡œë“œë¡œ ë°˜í™˜
        return False, incorrect_questions_list
    


# =====================================
# âš ï¸ ì£¼ì˜: ì•„ë˜ ì½”ë“œëŠ” í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤
# =====================================
# ì´ ë¸”ë¡ì€ ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤ (python blip_module.py)
# ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ importí•  ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì„œë²„ ì¶”ë¡ ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
if __name__ == "__main__":

    # --- 1. í…ŒìŠ¤íŠ¸ ì„¤ì • ---
    test_image_name = "test4.jpg"
    test_landmark = "ë„¤ëª¨íƒ‘" 

    # --- 2. í…ŒìŠ¤íŠ¸ ê²½ë¡œ ì„¤ì • ---
    test_image_path = os.path.join(PROJECT_ROOT, "metadata", "test_image", test_image_name)

    print("="*30)
    print("  BLIP Module Standalone Test (v2)  ")
    print("="*30)

    # --- 3. ì‹¤í–‰ ì „ ê¸°ë³¸ í™•ì¸ ---
    if not processor or not model:
        print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: BLIP ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    elif not landmark_qa_data:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {LANDMARK_QA_FILE} íŒŒì¼ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    elif not landmark_qa_data.get(test_landmark):
        print(
            f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: '{LANDMARK_QA_FILE}'ì— '{test_landmark}' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        )
    elif not os.path.exists(test_image_path):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   (ê²½ë¡œ: {test_image_path})")
    else:
        # --- 4. ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰ ---
        print(f"â–¶ï¸ Test Image: {test_image_path}")
        print(f"â–¶ï¸ Test Landmark: {test_landmark}")
        print("Running check_with_blip...")

        try:
            is_success, hint_payload = check_with_blip(test_image_path, test_landmark)

            print("\n--- ğŸ’¡ Test Result ---")
            print(f"Success: {is_success}")
            
            if not is_success:
                print("Hint Payload (Incorrect Answers):")
                for item in hint_payload:
                    print(f"  - Question: {item['question']}")
                    print(f"    Model Answer: '{item['model_answer']}', Expected: '{item['expected_answer']}'")
            else:
                print("Hint Payload is empty, mission successful!")

            print("-----------------------")

        except Exception as e:
            print(f"\n--- âŒ Test Failed with Runtime Exception ---")
            print(f"Error: {e}")
            if "cannot read HEIC file" in str(e):
                print("\n[ì•Œë¦¼] .HEIC íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(
                    "í„°ë¯¸ë„ì—ì„œ 'pip install pillow-heif'ë¥¼ ì‹¤í–‰í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                )
            print("---------------------------------------------")
