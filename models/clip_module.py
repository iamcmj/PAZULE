# clip_module.py
import os
import re
import sys
import json
import torch
from PIL import Image

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
from utils.clip_loader import clip_model, clip_processor, device
from config.keyword import keyword_mapping, kw_strong, kw_middle, kw_weak, rules, feedback_guide

def make_label_pairs(keyword_mapping):
    label_pairs = []
    for _, value in keyword_mapping.items():
        for v in value:
            label_pairs.append(v)
    return label_pairs


def make_prompts_from_keywords(keywords, templates=None):
    if templates is None:
        templates = [
            "A photo that conveys a {} mood.",
            "An image evoking a feeling of {}.",
            "A picture that feels {}.",
            # "A scene with a {} atmosphere.", # í•„ìš”ì‹œ ì¶”ê°€í•  ê²ƒ
            # "A photo expressing {} emotions."
        ]

    prompts = []
    for kw in keywords:
        tmp = []
        for t in templates:
            tmp.append(t.format(kw))
        prompts.append(" ".join(tmp))

    return prompts


def analyze_mood(image, keywords, top):
    prompts = make_prompts_from_keywords(keywords)
    inputs = clip_processor(
        text=prompts, images=image, return_tensors="pt", padding=True
    ).to(device)
    outputs = clip_model(**inputs)

    logits_per_image = outputs.logits_per_image
    probs = logits_per_image.softmax(dim=1)

    topk = torch.topk(probs, k=top)
    top_keywords = []
    scores = []

    for idx, score in zip(topk.indices[0].tolist(), topk.values[0].tolist()):
        match = re.search(r"conveys a (.+?) mood", prompts[idx])
        kw = match.group(1)
        top_keywords.append(kw)
        scores.append(f"{score*100:.1f}")

    return top_keywords, scores


def find_mood(target):
    for key, values in keyword_mapping.items():
        if target in values:
            return key

def make_answer(state, kw, top_mood, top_mood_specific):
    if state == "perfect":
        result = f"ì™„ë²½í•©ë‹ˆë‹¤!!ğŸ¥³ {kw} ëŠë‚Œì„ ì•„ì£¼ ì˜ ë‹´ìœ¼ì…¨ì–´ìš”!"
        
    elif state == "good":
        result = f"í›Œë¥­í•©ë‹ˆë‹¤â˜ºï¸ {kw} ëŠë‚Œì´ ì˜ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤!"
        
    elif state == "not_bad":
        result = f"ì¡°ê¸ˆë§Œ ë” {kw} ëŠë‚Œì„ ë‹´ì•„ ë³´ì„¸ìš”ğŸ™‚ í˜„ì¬ëŠ” {top_mood[0]} ëŠë‚Œì´ ë” ê°•í•©ë‹ˆë‹¤!\n"
        result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ê°•í•˜ê²Œ ì¸ì‹í•œ í‚¤ì›Œë“œ 2ê°œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
        for i, m in enumerate(top_mood_specific):
            result += f"{i+1}. {m}({top_mood[i]})\n"
            if i == 1:
                break

    elif state == "bad":
        result = f"ì•„ì‰½ìŠµë‹ˆë‹¤...ğŸ¥² {kw} ê°ì„±ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ì¸ì‹í•œ í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n"
        for i, m in enumerate(top_mood_specific):
            result += f"{i+1}. {m}({top_mood[i]})\n"
        result += f"\nğŸ’¡ {feedback_guide[kw]['desc']}\n\n"
        result += "ğŸ“· ì´ëŸ¬í•œ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”:\n"
        for eng, kor in feedback_guide[kw]["keywords"].items():
            result += f" - {kor}\n"
    
    return result

def check_with_clip(image, kw):
    print(f"ì˜¤ëŠ˜ì˜ ë¯¸ì…˜: {kw} ë¶„ìœ„ê¸°, ê°ì„±ì„ ì§€ë‹ˆê³  ìˆëŠ” ê³³ì„ ì§ì ‘ ì°ì–´ë³´ì„¸ìš”!")

    # ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°)
    if isinstance(image_path, str):
        image = Image.open(image_path).convert("RGB")
    else:
        image = image_path  # ì´ë¯¸ PIL Image ê°ì²´ì¸ ê²½ìš°

    label_pairs = make_label_pairs(keyword_mapping)

    if kw in kw_strong:
        top_keywords, scores = analyze_mood(image, label_pairs, 5)
        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(feedback_guide[find_mood(key)]["keywords"][key])

        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        is_success = False
        if top_mood[0] == kw and top_mood[1] == kw:
            result = make_answer("perfect", kw, top_mood, top_mood_specific)
            
        elif top_mood[0] == kw or sum(k == kw for k in top_mood) >= 3:
            result = make_answer("good", kw, top_mood, top_mood_specific)
            
        elif kw in top_mood:
            result = make_answer("not_bad", kw, top_mood, top_mood_specific)
                
        else:
            result = make_answer("bad", kw, top_mood, top_mood_specific)

    elif kw in kw_middle:
        top_keywords, scores = analyze_mood(image, label_pairs, 7)
        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(feedback_guide[find_mood(key)]["keywords"][key])

        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        is_success = False
        if top_mood[0] == kw or sum(k == kw for k in top_mood[:5]) >= 2:
            result = make_answer("perfect", kw, top_mood, top_mood_specific)
            
        elif sum(k == kw for k in top_mood) >= 2:
            result = make_answer("good", kw, top_mood, top_mood_specific)

        elif kw in top_mood:
            result = make_answer("not_bad", kw, top_mood, top_mood_specific)

        else:
            result = make_answer("bad", kw, top_mood, top_mood_specific)
        

    elif kw in kw_weak:
        top_keywords, scores = analyze_mood(image, label_pairs, 9)
        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(feedback_guide[find_mood(key)]["keywords"][key])

        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        is_success = False
        if top_mood[0] == kw or sum(k == kw for k in top_mood[:7]) >= 2:
            result = make_answer("perfect", kw, top_mood, top_mood_specific)
        elif kw in top_mood[:7]:
            result = make_answer("good", kw, top_mood, top_mood_specific)
        elif kw in top_mood:
            result = make_answer("not_bad", kw, top_mood, top_mood_specific)
        else:
            result = make_answer("bad", kw, top_mood, top_mood_specific)
    
    print(result)
        
        
if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    # ëŒë ¤ë³´ê³  ì‹¶ìœ¼ë©´ python models/clip_module.py
    
    kw = "ì›…ì¥í•œ"
    image_path = os.path.join(PROJECT_ROOT, "data", "ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ", "IMG_9802.jpg")
    image = Image.open(image_path).convert("RGB")

    check_with_clip(image, kw)
