{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea28cace",
   "metadata": {},
   "source": [
    "# BLIP ê¸°ë°˜ ëœë“œë§ˆí¬ ì´ë¯¸ì§€ ì¸ì‹ ë° ê²€ì¦ ì‹œìŠ¤í…œ\n",
    "\n",
    "3ê°€ì§€ ê²€ì¦ ë°©ì‹ ì œê³µ:\n",
    "1. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (BlipForImageTextRetrieval)\n",
    "2. í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (ìº¡ì…˜ ìƒì„± + SBERT)\n",
    "3. VQA ìœ ì‚¬ë„ ê²€ì¦ (ì§ˆë¬¸-ë‹µë³€ ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (BlipProcessor,\n",
    "                          BlipForImageTextRetrieval,\n",
    "                          BlipForConditionalGeneration,\n",
    "                          BlipForQuestionAnswering)\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import files, drive\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# GPU ì‚¬ìš© ì„¤ì •\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ìºì‹œ (lazy loading ìš©)\n",
    "_models_cache = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eadfe6",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8cae26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IN_COLAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(current_file / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ê¸°ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m DATA_DIR = \u001b[43msetup_data_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36msetup_data_directory\u001b[39m\u001b[34m(custom_path)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m custom_path:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m custom_path\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mIN_COLAB\u001b[49m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Colab í™˜ê²½: Google Drive ë§ˆìš´íŠ¸ ì‹œë„\u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     21\u001b[39m         drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive/\u001b[39m\u001b[33m'\u001b[39m, force_remount=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'IN_COLAB' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "# ============================================================================\n",
    "\n",
    "def setup_data_directory(custom_path=None):\n",
    "    \"\"\"\n",
    "    ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        custom_path: ì‚¬ìš©ì ì§€ì • ê²½ë¡œ (Noneì´ë©´ ìë™ ê°ì§€)\n",
    "    \n",
    "    Returns:\n",
    "        data_dir: ì„¤ì •ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \"\"\"\n",
    "    if custom_path:\n",
    "        return custom_path\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        # Colab í™˜ê²½: Google Drive ë§ˆìš´íŠ¸ ì‹œë„\n",
    "        try:\n",
    "            drive.mount('/content/drive/', force_remount=False)\n",
    "            return \"/content/drive/MyDrive/íŒŒì£¼ AI í”„ë¡œì íŠ¸/data\"\n",
    "        except Exception as e:\n",
    "            print(f\"Google Drive ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "            return \"/content/data\"\n",
    "    else:\n",
    "        # ë¡œì»¬ í™˜ê²½: ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "        current_file = Path(__file__).parent\n",
    "        return str(current_file / \"data\")\n",
    "\n",
    "# ê¸°ë³¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "DATA_DIR = setup_data_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bde206",
   "metadata": {},
   "source": [
    "## 2. ëª¨ë¸ ë¡œë“œ (Lazy Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf3db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. ëª¨ë¸ ë¡œë“œ (Lazy Loading)\n",
    "# ============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def load_model(mode):\n",
    "    \"\"\"\n",
    "    BLIP ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ìºì‹± ì§€ì›)\n",
    "    \n",
    "    Args:\n",
    "        mode: ëª¨ë¸ ëª¨ë“œ (\"captioning\", \"matching\", \"vqa\")\n",
    "    \n",
    "    Returns:\n",
    "        processor, model: ë¡œë“œëœ í”„ë¡œì„¸ì„œì™€ ëª¨ë¸\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ ë¡œë“œëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë°˜í™˜\n",
    "    if mode in _models_cache:\n",
    "        return _models_cache[mode]\n",
    "    \n",
    "    print(f\"[{mode}] ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘... (ì¥ì¹˜: {device})\")\n",
    "    \n",
    "    try:\n",
    "        if mode == \"captioning\":\n",
    "            model_name = \"Salesforce/blip-image-captioning-base\"\n",
    "            processor = BlipProcessor.from_pretrained(model_name)\n",
    "            model = BlipForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "        elif mode == \"matching\":\n",
    "            model_name = \"Salesforce/blip-itm-base-coco\"\n",
    "            processor = BlipProcessor.from_pretrained(model_name)\n",
    "            model = BlipForImageTextRetrieval.from_pretrained(model_name).to(device)\n",
    "        elif mode == \"vqa\":\n",
    "            model_name = \"ybelkada/blip-vqa-base\"\n",
    "            processor = BlipProcessor.from_pretrained(model_name)\n",
    "            model = BlipForQuestionAnswering.from_pretrained(model_name).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ: {mode}. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ: 'captioning', 'matching', 'vqa'\")\n",
    "        \n",
    "        model.eval()\n",
    "        _models_cache[mode] = (processor, model)\n",
    "        print(f\"[{mode}] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "        \n",
    "        return processor, model\n",
    "    except Exception as e:\n",
    "        print(f\"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_sbert_model():\n",
    "    \"\"\"SBERT ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ìºì‹± ì§€ì›)\"\"\"\n",
    "    if \"sbert\" not in _models_cache:\n",
    "        print(f\"SBERT ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘... (ì¥ì¹˜: {device})\")\n",
    "        _models_cache[\"sbert\"] = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "        print(\"SBERT ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    return _models_cache[\"sbert\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9b5fa",
   "metadata": {},
   "source": [
    "## 3. Ground Truth ìº¡ì…˜ ì •ì˜ (ëœë“œë§ˆí¬ ì´ë¯¸ì§€ í´ë”ì—ì„œ ìë™ ìƒì„±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f76bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. Ground Truth ìº¡ì…˜ ì •ì˜ (ëœë“œë§ˆí¬ ì´ë¯¸ì§€ í´ë”ì—ì„œ ìë™ ìƒì„±)\n",
    "# ============================================================================\n",
    "\n",
    "def find_images_in_directory(directory):\n",
    "    \"\"\"\n",
    "    ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ëŠ” í•¨ìˆ˜ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ìŒ)\n",
    "    \n",
    "    Args:\n",
    "        directory: ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    \n",
    "    Returns:\n",
    "        image_files: ì°¾ì€ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    image_extensions = [\"jpg\", \"jpeg\", \"png\", \"webp\", \"jfif\", \"bmp\", \"gif\"]\n",
    "    image_files = []\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        return []\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            ext = file.lower().split('.')[-1]\n",
    "            if ext in image_extensions:\n",
    "                image_files.append(file_path)\n",
    "    \n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth_captions_from_folder(landmark_name, data_dir=None, prompt_text=None):\n",
    "    \"\"\"\n",
    "    ëœë“œë§ˆí¬ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ Ground Truth ìº¡ì…˜ì„ ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        landmark_name: ëœë“œë§ˆí¬ ì´ë¦„ (í´ë” ì´ë¦„)\n",
    "        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
    "        prompt_text: ì„ íƒì  í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ (ì˜ˆ: \"this place is\")\n",
    "    \n",
    "    Returns:\n",
    "        all_captions: ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ ìƒì„±ëœ ê³ ìœ  ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    cap_processor, cap_model = load_model(\"captioning\")\n",
    "    \n",
    "    # ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "    if data_dir is None:\n",
    "        data_dir = DATA_DIR\n",
    "    \n",
    "    landmark_dir = os.path.join(data_dir, landmark_name)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
    "    image_files = find_images_in_directory(landmark_dir)\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"ê²½ê³ : '{landmark_dir}' í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"'{landmark_name}' í´ë”ì—ì„œ ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"Ground Truth ìº¡ì…˜ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    all_captions_set = set()  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ set\n",
    "    failed_images = 0\n",
    "    \n",
    "    for img_path in tqdm(image_files, desc=f\"'{landmark_name}' ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘\"):\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            # ìº¡ì…˜ ìƒì„±\n",
    "            if prompt_text:\n",
    "                inputs = cap_processor(images=image, text=prompt_text, return_tensors=\"pt\").to(device)\n",
    "            else:\n",
    "                inputs = cap_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            # Greedy ë””ì½”ë”©ìœ¼ë¡œ ê¸°ë³¸ ìº¡ì…˜ ìƒì„±\n",
    "            outputs_greedy = cap_model.generate(**inputs, max_length=50)\n",
    "            caption_greedy = cap_processor.decode(outputs_greedy[0], skip_special_tokens=True).strip()\n",
    "            \n",
    "            if caption_greedy and caption_greedy.lower() not in [\"none\", \"unanswerable\", \"\"]:\n",
    "                all_captions_set.add(caption_greedy)\n",
    "            \n",
    "            # ë‹¤ì–‘í•œ ìº¡ì…˜ ìƒì„± (Nucleus Sampling)\n",
    "            outputs_diverse = cap_model.generate(\n",
    "                **inputs,\n",
    "                max_length=50,\n",
    "                num_beams=5,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                num_return_sequences=3\n",
    "            )\n",
    "            \n",
    "            for output in outputs_diverse:\n",
    "                caption = cap_processor.decode(output, skip_special_tokens=True).strip()\n",
    "                if caption and caption.lower() not in [\"none\", \"unanswerable\", \"\"]:\n",
    "                    all_captions_set.add(caption)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            failed_images += 1\n",
    "            if failed_images <= 3:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥\n",
    "                print(f\"\\n{os.path.basename(img_path)} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    \n",
    "    all_captions = list(all_captions_set)\n",
    "    print(f\"\\nìƒì„±ëœ Ground Truth ìº¡ì…˜ ìˆ˜: {len(all_captions)}\")\n",
    "    if failed_images > 0:\n",
    "        print(f\"ì²˜ë¦¬ ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ìˆ˜: {failed_images}\")\n",
    "    \n",
    "    return all_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_image_caption(image, prompt_text=None):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ ì´ë¯¸ì§€ë¡œë¶€í„° ìº¡ì…˜ ìƒì„± (Ground Truth ìƒì„±ìš©)\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image ê°ì²´\n",
    "        prompt_text: ì„ íƒì  í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        generated_captions: ìƒì„±ëœ ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    cap_processor, cap_model = load_model(\"captioning\")\n",
    "    \n",
    "    print(\"\\n--- AIê°€ Ground Truth ìº¡ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤ ---\")\n",
    "    \n",
    "    try:\n",
    "        if prompt_text:\n",
    "            inputs = cap_processor(images=image, text=prompt_text, return_tensors=\"pt\").to(device)\n",
    "        else:\n",
    "            inputs = cap_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # ê¸°ë³¸ ìº¡ì…˜ ìƒì„±\n",
    "        outputs_greedy = cap_model.generate(**inputs, max_length=50)\n",
    "        caption_greedy = cap_processor.decode(outputs_greedy[0], skip_special_tokens=True)\n",
    "        print(f\"  [ê¸°ë³¸ ìº¡ì…˜]: {caption_greedy}\")\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ ìº¡ì…˜ ìƒì„±\n",
    "        print(\"\\n[ë‹¤ì–‘í•œ ìº¡ì…˜ (JSON í›„ë³´ 3ê°œ)]:\")\n",
    "        outputs_diverse = cap_model.generate(\n",
    "            **inputs,\n",
    "            max_length=50,\n",
    "            num_beams=5,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            num_return_sequences=3\n",
    "        )\n",
    "        \n",
    "        generated_captions = []\n",
    "        for i, output in enumerate(outputs_diverse):\n",
    "            caption = cap_processor.decode(output, skip_special_tokens=True)\n",
    "            if caption not in generated_captions and caption != caption_greedy:\n",
    "                generated_captions.append(caption)\n",
    "            print(f\"  - (í›„ë³´ {i+1}): {caption}\")\n",
    "        \n",
    "        if caption_greedy not in generated_captions:\n",
    "            generated_captions.insert(0, caption_greedy)\n",
    "        \n",
    "        # JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥\n",
    "        print(\"\\n--- 'missions.json'ì˜ [ground_truth_captions]ì— ë³µì‚¬í•  ë‚´ìš© ---\")\n",
    "        print('[')\n",
    "        for i, cap in enumerate(generated_captions):\n",
    "            print(f'  \"{cap}\"{\",\" if i < len(generated_captions) - 1 else \"\"}')\n",
    "        print(']')\n",
    "        \n",
    "        return generated_captions\n",
    "    except Exception as e:\n",
    "        print(f\"ìº¡ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bf003",
   "metadata": {},
   "source": [
    "## 4. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_image_text_similarity(user_image, gt_captions, threshold_low=0.5, threshold_high=0.8):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ìº¡ì…˜ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ê²€ì¦\n",
    "    \n",
    "    Args:\n",
    "        user_image: PIL Image ê°ì²´\n",
    "        gt_captions: Ground Truth ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "        threshold_low: ë‚®ì€ ì„ê³„ê°’\n",
    "        threshold_high: ë†’ì€ ì„ê³„ê°’\n",
    "    \n",
    "    Returns:\n",
    "        best_score: ìµœê³  ë§¤ì¹­ ì ìˆ˜ (0~1)\n",
    "        feedback: í”¼ë“œë°± ë©”ì‹œì§€\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    mat_processor, mat_model = load_model(\"matching\")\n",
    "    \n",
    "    if not gt_captions:\n",
    "        return 0.0, \"ì˜¤ë¥˜: Ground Truth ìº¡ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    match_scores = []\n",
    "    \n",
    "    print(\"\\n[1. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦]\")\n",
    "    print(\"AIê°€ ì‚¬ì§„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    try:\n",
    "        for gt_caption in gt_captions:\n",
    "            # ì´ë¯¸ì§€ì™€ ì •ë‹µ ìº¡ì…˜ì„ ëª¨ë¸ì´ ì´í•´í•˜ë„ë¡ ì²˜ë¦¬\n",
    "            inputs = mat_processor(images=user_image, text=gt_caption, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            # ITC ë¡œì§“(ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì ìˆ˜)ì„ í…ì„œë¡œ ê°€ì ¸ì˜´\n",
    "            cosine_score = mat_model(**inputs, use_itm_head=False)[0]\n",
    "            \n",
    "            # sigmoid í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ [0, 1] í™•ë¥ ë¡œ ë³€í™˜\n",
    "            prob_score_tensor = torch.sigmoid(cosine_score)\n",
    "            prob_score_float = prob_score_tensor.item()\n",
    "            \n",
    "            match_scores.append(prob_score_float)\n",
    "        \n",
    "        # ê°€ì¥ ë†’ì€ ë§¤ì¹­ ì ìˆ˜ë¥¼ ìµœì¢… ì ìˆ˜ë¡œ ì‚¬ìš©\n",
    "        best_score = max(match_scores)\n",
    "        \n",
    "        print(f\"\\n[AI ë¶„ì„ ê²°ê³¼] ìµœê³  ë§¤ì¹­ ì ìˆ˜: {best_score*100:.2f}ì \")\n",
    "        \n",
    "        # í”¼ë“œë°± ìƒì„±\n",
    "        if best_score > threshold_high:\n",
    "            feedback = \"ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤! ë¯¸ì…˜ ì„±ê³µ!\"\n",
    "        elif best_score > threshold_low:\n",
    "            feedback = f\"ğŸ¤” ì˜¤! ê±°ì˜ ê·¼ì ‘í–ˆì–´ìš”! (ì ìˆ˜: {best_score*100:.2f}ì )\"\n",
    "        else:\n",
    "            feedback = f\"ì•„ì‰½ë„¤ìš”. íŒíŠ¸ì™€ëŠ” ì¡°ê¸ˆ ë‹¤ë¥¸ ê²ƒ ê°™ì•„ìš”. (ì ìˆ˜: {best_score*100:.2f}ì )\"\n",
    "        \n",
    "        return best_score, feedback\n",
    "    except Exception as e:\n",
    "        print(f\"ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return 0.0, f\"ì˜¤ë¥˜: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2cc4a4",
   "metadata": {},
   "source": [
    "## 5. í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4adb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_text_text_similarity(user_image, gt_captions, threshold_low=0.5, threshold_high=0.8):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì´ë¯¸ì§€ì—ì„œ ìº¡ì…˜ì„ ìƒì„±í•œ í›„, Ground Truth ìº¡ì…˜ë“¤ê³¼ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ë¥¼ ë¹„êµ\n",
    "    \n",
    "    Args:\n",
    "        user_image: PIL Image ê°ì²´\n",
    "        gt_captions: Ground Truth ìº¡ì…˜ ë¦¬ìŠ¤íŠ¸\n",
    "        threshold_low: ë‚®ì€ ì„ê³„ê°’\n",
    "        threshold_high: ë†’ì€ ì„ê³„ê°’\n",
    "    \n",
    "    Returns:\n",
    "        best_score: ìµœê³  ìœ ì‚¬ë„ ì ìˆ˜ (0~1)\n",
    "        user_caption: ìƒì„±ëœ ì‚¬ìš©ì ì´ë¯¸ì§€ ìº¡ì…˜\n",
    "        feedback: í”¼ë“œë°± ë©”ì‹œì§€\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    cap_processor, cap_model = load_model(\"captioning\")\n",
    "    sbert_model = load_sbert_model()\n",
    "    \n",
    "    if not gt_captions:\n",
    "        return 0.0, \"\", \"ì˜¤ë¥˜: Ground Truth ìº¡ì…˜ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    print(\"\\n[2. í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦]\")\n",
    "    print(\"AIê°€ ì‚¬ì§„ ìº¡ì…˜ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    try:\n",
    "        # ì‚¬ìš©ì ì‚¬ì§„ìœ¼ë¡œ ìº¡ì…˜ ìƒì„±\n",
    "        inputs_cap = cap_processor(images=user_image, return_tensors=\"pt\").to(device)\n",
    "        outputs_cap = cap_model.generate(**inputs_cap, max_length=50)\n",
    "        user_caption = cap_processor.decode(outputs_cap[0], skip_special_tokens=True)\n",
    "        print(f\"  [ìƒì„±ëœ ìº¡ì…˜]: {user_caption}\")\n",
    "        \n",
    "        print(\"ìƒì„±ëœ ìº¡ì…˜ê³¼ ì •ë‹µ ìº¡ì…˜ë“¤ì˜ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•©ë‹ˆë‹¤...\")\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (SBERT)\n",
    "        user_embedding = sbert_model.encode([user_caption])\n",
    "        gt_embeddings = sbert_model.encode(gt_captions)\n",
    "        \n",
    "        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "        sim_scores = cosine_similarity(user_embedding, gt_embeddings)\n",
    "        best_score = np.max(sim_scores)\n",
    "        \n",
    "        print(f\"\\n[AI ë¶„ì„ ê²°ê³¼] ìµœê³  ìº¡ì…˜ ìœ ì‚¬ë„: {best_score*100:.2f}ì \")\n",
    "        \n",
    "        # í”¼ë“œë°± ìƒì„±\n",
    "        if best_score > threshold_high:\n",
    "            feedback = \"ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤! ë¯¸ì…˜ ì„±ê³µ!\"\n",
    "        elif best_score > threshold_low:\n",
    "            feedback = f\"ğŸ¤” ì˜¤! ê±°ì˜ ê·¼ì ‘í–ˆì–´ìš”! (ì ìˆ˜: {best_score*100:.2f}ì )\"\n",
    "        else:\n",
    "            feedback = f\"ì•„ì‰½ë„¤ìš”. íŒíŠ¸ì™€ëŠ” ì¡°ê¸ˆ ë‹¤ë¥¸ ê²ƒ ê°™ì•„ìš”. (ì ìˆ˜: {best_score*100:.2f}ì )\"\n",
    "        \n",
    "        return best_score, user_caption, feedback\n",
    "    except Exception as e:\n",
    "        print(f\"í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return 0.0, \"\", f\"ì˜¤ë¥˜: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689146f",
   "metadata": {},
   "source": [
    "## 6. ì§ˆë¬¸ ì„¸íŠ¸ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fcbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. ì§ˆë¬¸ ì„¸íŠ¸ ì •ë¦¬\n",
    "# ============================================================================\n",
    "\n",
    "# ëœë“œë§ˆí¬ë³„ ì§ˆë¬¸ ì„¸íŠ¸ ì •ì˜\n",
    "QUESTIONS = {\n",
    "    \"í”¼ë…¸í‚¤ì˜¤\": [\n",
    "        \"Is there a prominent human-shaped statue in the picture?\",\n",
    "        \"If there is a statue, is it a character from a fairy tale?\",\n",
    "        \"Does the statue have a particularly long nose?\",\n",
    "        \"Is the statue wearing green-colored clothes?\",\n",
    "        \"Are there flower patterns on the statue's clothes?\",\n",
    "        \"Is the statue holding something?\",\n",
    "        \"Is the object the statue is holding a book?\",\n",
    "        \"Is the hat the statue is wearing a pointed cone shape?\",\n",
    "        \"Are the statue's arms relatively thin and long?\",\n",
    "        \"Is the statue holding up a finger with its right hand, like the number 1?\"\n",
    "    ],\n",
    "    \"ë„¤ëª¨íƒ‘\": [\n",
    "        \"Is this object shaped like a tower?\",\n",
    "        \"Is this tower shaped like stacked square boxes?\",\n",
    "        \"Is the height much longer than the width?\",\n",
    "        \"Is this object made of wood?\",\n",
    "        \"Is the color reddish-brown?\",\n",
    "        \"Does the color look like rusty metal?\",\n",
    "        \"Is the surface smooth?\",\n",
    "        \"Does the sculpture only use dark colors?\",\n",
    "        \"Does this sculpture have many layers?\",\n",
    "        \"Is the number of layers exactly 5?\",\n",
    "        \"Do the layers get smaller as they go up?\",\n",
    "        \"Is the bottom part the widest?\",\n",
    "        \"Does each layer have a square opening on the front?\",\n",
    "        \"Does the height of this sculpture look more than twice a person's height?\"\n",
    "    ],\n",
    "    \"ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ\": [\n",
    "        \"Is this picture taken inside a building?\",\n",
    "        \"Does the background show a place with many books?\",\n",
    "        \"Do wooden bookshelves cover the walls?\",\n",
    "        \"Does the room have a high ceiling?\",\n",
    "        \"Is the floor made of wood?\",\n",
    "        \"Is the main object a human-shaped sculpture?\",\n",
    "        \"Is the sculpture sitting down?\",\n",
    "        \"Does the sculpture have its hands near its face?\",\n",
    "        \"Is the sculpture holding binoculars?\",\n",
    "        \"Is the sculpture looking straight ahead?\",\n",
    "        \"Does the sculpture wear a suit?\",\n",
    "        \"Is the suit covered in many bright colors?\",\n",
    "        \"Does the suit have patterns like flowers?\",\n",
    "        \"Does the sculpture's suit have a lot of green and yellow?\",\n",
    "        \"Is the sculpture's face also painted with patterns?\",\n",
    "        \"Is the sculpture sitting on a square base?\",\n",
    "        \"Does the base look like it is made of stacked small blocks?\",\n",
    "        \"Does the base have letters written on it?\",\n",
    "        \"Is a small container placed next to the sculpture?\",\n",
    "        \"Does that small container have patterns on it too?\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3da91",
   "metadata": {},
   "source": [
    "## 7. VQA ìœ ì‚¬ë„ ê²€ì¦ (ì§ˆë¬¸ ê¸°ë°˜ YES ë¹„ìœ¨ë¡œ íŒì •)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. VQA ìœ ì‚¬ë„ ê²€ì¦ (ì§ˆë¬¸ ê¸°ë°˜ YES ë¹„ìœ¨ë¡œ íŒì •)\n",
    "# ============================================================================\n",
    "\n",
    "def verify_vqa_similarity(user_image, landmark_name, required_yes_ratio=0.75):\n",
    "    \"\"\"\n",
    "    VQA ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸-ë‹µë³€ ê¸°ë°˜ìœ¼ë¡œ ëœë“œë§ˆí¬ ì¸ì‹ ê²€ì¦\n",
    "    Ground Truth ìº¡ì…˜ì´ ì•„ë‹Œ ì§ˆë¬¸ì— ëŒ€í•œ YES ë¹„ìœ¨ë¡œ íŒì •\n",
    "    \n",
    "    Args:\n",
    "        user_image: PIL Image ê°ì²´\n",
    "        landmark_name: ëœë“œë§ˆí¬ ì´ë¦„ (QUESTIONS ë”•ì…”ë„ˆë¦¬ì˜ í‚¤)\n",
    "        required_yes_ratio: ì •ë‹µìœ¼ë¡œ íŒì •í•  YES ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.75)\n",
    "    \n",
    "    Returns:\n",
    "        yes_ratio: YES ë‹µë³€ ë¹„ìœ¨ (0~1)\n",
    "        feedback: í”¼ë“œë°± ë©”ì‹œì§€\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ë¡œë“œ\n",
    "    vqa_processor, vqa_model = load_model(\"vqa\")\n",
    "    \n",
    "    print(\"\\n[3. VQA ìœ ì‚¬ë„ ê²€ì¦]\")\n",
    "    print(\"AIê°€ ì‚¬ì§„ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "    if landmark_name not in QUESTIONS:\n",
    "        return None, f\"ì˜¤ë¥˜: '{landmark_name}'ëŠ” ì •ì˜ë˜ì§€ ì•Šì€ ëœë“œë§ˆí¬ ì´ë¦„ì…ë‹ˆë‹¤.\"\n",
    "    \n",
    "    landmark_questions = QUESTIONS[landmark_name]\n",
    "    yes_count = 0\n",
    "    total_questions = len(landmark_questions)\n",
    "    \n",
    "    if total_questions == 0:\n",
    "        return None, f\"ê²½ê³ : '{landmark_name}'ì— ëŒ€í•œ ì§ˆë¬¸ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    try:\n",
    "        for question in tqdm(landmark_questions, desc=f\"VQA ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘\"):\n",
    "            try:\n",
    "                # VQA ëª¨ë¸ì— ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ ì „ë‹¬\n",
    "                inputs = vqa_processor(user_image, question, return_tensors=\"pt\").to(device)\n",
    "                \n",
    "                # ë‹µë³€ ìƒì„± (max_lengthë¥¼ ì§§ê²Œ í•˜ì—¬ ë‹¨ë‹µí˜• ìœ ë„)\n",
    "                out = vqa_model.generate(**inputs, max_length=20)\n",
    "                answer = vqa_processor.decode(out[0], skip_special_tokens=True).strip().lower()\n",
    "                \n",
    "                # 'yes' ê°œìˆ˜ ì„¸ê¸°\n",
    "                if answer == 'yes':\n",
    "                    yes_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"\\nì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        \n",
    "        # YES ë¹„ìœ¨ ê³„ì‚°\n",
    "        yes_ratio = (yes_count / total_questions) if total_questions > 0 else 0\n",
    "        print(f\"\\nì´ ì§ˆë¬¸ ìˆ˜: {total_questions}, 'yes' ë‹µë³€ ìˆ˜: {yes_count}\")\n",
    "        print(f\"YES ë¹„ìœ¨: {yes_ratio*100:.2f}%\")\n",
    "        \n",
    "        # ê²°ê³¼ íŒì • (YES ë¹„ìœ¨ ê¸°ì¤€)\n",
    "        if yes_ratio >= required_yes_ratio:\n",
    "            feedback = f\"ğŸ‰ ì •ë‹µì…ë‹ˆë‹¤! ì…ë ¥ëœ ì‚¬ì§„ì€ '{landmark_name}'ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. (YES ë¹„ìœ¨: {yes_ratio*100:.2f}%)\"\n",
    "        else:\n",
    "            feedback = f\"ğŸ¤” ì•„ì‰½ë„¤ìš”. ì…ë ¥ëœ ì‚¬ì§„ì€ '{landmark_name}'ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. (YES ë¹„ìœ¨: {yes_ratio*100:.2f}%)\"\n",
    "        \n",
    "        return yes_ratio, feedback\n",
    "    except Exception as e:\n",
    "        print(f\"VQA ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None, f\"ì˜¤ë¥˜: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5dd8f6",
   "metadata": {},
   "source": [
    "## 8. ë¯¸ì…˜ ì‹œìŠ¤í…œ (argumentë¡œ ê²€ì¦ ë°©ì‹ ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67941789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. ë¯¸ì…˜ ì‹œìŠ¤í…œ (argumentë¡œ ê²€ì¦ ë°©ì‹ ì„ íƒ)\n",
    "# ============================================================================\n",
    "\n",
    "def run_mission_verification(verification_method=\"image_text\", landmark_name=None, mission_data=None, \n",
    "                             image_path=None, data_dir=None):\n",
    "    \"\"\"\n",
    "    ë¯¸ì…˜ ê²€ì¦ ì‹œìŠ¤í…œ ì‹¤í–‰\n",
    "    \n",
    "    Args:\n",
    "        verification_method: ê²€ì¦ ë°©ë²• ì„ íƒ\n",
    "            - \"image_text\": ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (Ground Truth ìº¡ì…˜ í•„ìš”)\n",
    "            - \"text_text\": í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (Ground Truth ìº¡ì…˜ í•„ìš”)\n",
    "            - \"vqa\": VQA ìœ ì‚¬ë„ ê²€ì¦ (ì§ˆë¬¸ ì„¸íŠ¸ë§Œ í•„ìš”, Ground Truth ìº¡ì…˜ ë¶ˆí•„ìš”)\n",
    "        landmark_name: ëœë“œë§ˆí¬ ì´ë¦„ (VQA ê²€ì¦ ì‹œ í•„ìˆ˜, ë‹¤ë¥¸ ê²€ì¦ ì‹œ Ground Truth ìƒì„±ì— ì‚¬ìš©)\n",
    "        mission_data: ë¯¸ì…˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
    "        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ë¡œì»¬ í™˜ê²½ìš©, Noneì´ë©´ ì—…ë¡œë“œ ì‚¬ìš©)\n",
    "        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    # ë¯¸ì…˜ ë°ì´í„° ì„¤ì •\n",
    "    if mission_data is None:\n",
    "        mission_data = {\n",
    "            \"id\": 1,\n",
    "            \"daily_keyword\": \"ì§€ì‹\",\n",
    "            \"landmark_name\": \"ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ\",\n",
    "            \"hint_text_1\": \"ìˆ˜ë§Œ ê¶Œì˜ ì´ì•¼ê¸°ê°€ ìŒ“ì¸ ì‹œê°„ì˜ í”ì ì„ ì°¾ì•„ë³´ì„¸ìš”.\",\n",
    "            \"hint_text_2\": \"ë†’ì€ ì„œê°€ë“¤ì´ ìˆ²ì²˜ëŸ¼ ìš°ê±°ì§„ ê³³ì…ë‹ˆë‹¤.\",\n",
    "            \"hint_text_3\": \"ã…ˆã…ã…‡ ã…… (ì´ˆì„± íŒíŠ¸)\",\n",
    "            \"score_threshold_low\": 0.5,\n",
    "            \"score_threshold_high\": 0.8,\n",
    "            \"required_yes_ratio\": 0.75  # VQA ê²€ì¦ìš©\n",
    "        }\n",
    "    \n",
    "    # ëœë“œë§ˆí¬ ì´ë¦„ ì„¤ì •\n",
    "    if landmark_name is None:\n",
    "        landmark_name = mission_data.get(\"landmark_name\", \"ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ì˜¤ëŠ˜ì˜ ë¯¸ì…˜: #{mission_data['daily_keyword']}\")\n",
    "    print(f\"ëœë“œë§ˆí¬: {landmark_name}\")\n",
    "    print(f\"ê²€ì¦ ë°©ì‹: {verification_method}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\níŒíŠ¸: {mission_data['hint_text_1']}\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    try:\n",
    "        if image_path:\n",
    "            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš°\n",
    "            print(f\"\\nì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤: {image_path}\")\n",
    "            user_image = Image.open(image_path).convert(\"RGB\")\n",
    "            file_name = os.path.basename(image_path)\n",
    "        elif IN_COLAB:\n",
    "            # Colab í™˜ê²½: íŒŒì¼ ì—…ë¡œë“œ\n",
    "            print(\"\\nì •ë‹µì´ë¼ê³  ìƒê°í•˜ëŠ” ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”:\")\n",
    "            uploaded = files.upload()\n",
    "            \n",
    "            if len(uploaded) == 0:\n",
    "                print(\"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "                return\n",
    "            \n",
    "            file_name = list(uploaded.keys())[0]\n",
    "            user_image = Image.open(io.BytesIO(uploaded[file_name])).convert(\"RGB\")\n",
    "        else:\n",
    "            print(\"ì˜¤ë¥˜: ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "            print(\"ì‚¬ìš©ë²•: run_mission_verification(..., image_path='your_image.jpg')\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n[ì—…ë¡œë“œí•œ ì‚¬ì§„: {file_name}]\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ í‘œì‹œ (í™˜ê²½ì— ë”°ë¼)\n",
    "        if IN_COLAB:\n",
    "            try:\n",
    "                from IPython.display import display as ipy_display\n",
    "                ipy_display(user_image.resize((300, 300)))\n",
    "            except:\n",
    "                print(\"ì´ë¯¸ì§€ í‘œì‹œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(f\"ì´ë¯¸ì§€ í¬ê¸°: {user_image.size}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ê²€ì¦ ë°©ë²•ì— ë”°ë¼ ì‹¤í–‰\n",
    "    if verification_method == \"image_text\":\n",
    "        # Ground Truth ìº¡ì…˜ ìƒì„±\n",
    "        print(\"\\n[Ground Truth ìº¡ì…˜ ìƒì„± ì¤‘...]\")\n",
    "        gt_captions = generate_ground_truth_captions_from_folder(landmark_name, data_dir)\n",
    "        \n",
    "        if not gt_captions:\n",
    "            print(\"ê²½ê³ : Ground Truth ìº¡ì…˜ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\n",
    "        best_score, feedback = verify_image_text_similarity(\n",
    "            user_image,\n",
    "            gt_captions,\n",
    "            mission_data['score_threshold_low'],\n",
    "            mission_data['score_threshold_high']\n",
    "        )\n",
    "        print(f\"\\n{feedback}\")\n",
    "        \n",
    "        # íŒíŠ¸ ì œê³µ\n",
    "        if best_score > mission_data['score_threshold_low'] and best_score <= mission_data['score_threshold_high']:\n",
    "            print(f\"ğŸ’¡ íŒíŠ¸ 2: {mission_data['hint_text_2']}\")\n",
    "        elif best_score <= mission_data['score_threshold_low']:\n",
    "            print(f\"ğŸ’¡ ìµœì¢… íŒíŠ¸: {mission_data['hint_text_3']}\")\n",
    "        else:\n",
    "            print(\"(ë³´ìƒ: 100 ë§ˆì¼ë¦¬ì§€ ì ë¦½ ğŸ’°)\")\n",
    "    \n",
    "    elif verification_method == \"text_text\":\n",
    "        # Ground Truth ìº¡ì…˜ ìƒì„±\n",
    "        print(\"\\n[Ground Truth ìº¡ì…˜ ìƒì„± ì¤‘...]\")\n",
    "        gt_captions = generate_ground_truth_captions_from_folder(landmark_name, data_dir)\n",
    "        \n",
    "        if not gt_captions:\n",
    "            print(\"ê²½ê³ : Ground Truth ìº¡ì…˜ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\n",
    "        best_score, user_caption, feedback = verify_text_text_similarity(\n",
    "            user_image,\n",
    "            gt_captions,\n",
    "            mission_data['score_threshold_low'],\n",
    "            mission_data['score_threshold_high']\n",
    "        )\n",
    "        print(f\"\\n{feedback}\")\n",
    "        \n",
    "        # íŒíŠ¸ ì œê³µ\n",
    "        if best_score > mission_data['score_threshold_low'] and best_score <= mission_data['score_threshold_high']:\n",
    "            print(f\"ğŸ’¡ íŒíŠ¸ 2: {mission_data['hint_text_2']}\")\n",
    "        elif best_score <= mission_data['score_threshold_low']:\n",
    "            print(f\"ğŸ’¡ ìµœì¢… íŒíŠ¸: {mission_data['hint_text_3']}\")\n",
    "        else:\n",
    "            print(\"(ë³´ìƒ: 100 ë§ˆì¼ë¦¬ì§€ ì ë¦½ ğŸ’°)\")\n",
    "    \n",
    "    elif verification_method == \"vqa\":\n",
    "        # VQA ê²€ì¦ (Ground Truth ìº¡ì…˜ ë¶ˆí•„ìš”, ì§ˆë¬¸ ì„¸íŠ¸ë§Œ ì‚¬ìš©)\n",
    "        yes_ratio, feedback = verify_vqa_similarity(\n",
    "            user_image,\n",
    "            landmark_name,\n",
    "            mission_data.get('required_yes_ratio', 0.75)\n",
    "        )\n",
    "        print(f\"\\n{feedback}\")\n",
    "        \n",
    "        # íŒíŠ¸ ì œê³µ\n",
    "        if yes_ratio is not None:\n",
    "            if yes_ratio >= mission_data.get('required_yes_ratio', 0.75):\n",
    "                print(\"(ë³´ìƒ: 100 ë§ˆì¼ë¦¬ì§€ ì ë¦½ ğŸ’°)\")\n",
    "            elif yes_ratio >= 0.5:  # ì¤‘ê°„ ì •ë„\n",
    "                print(f\"ğŸ’¡ íŒíŠ¸ 2: {mission_data['hint_text_2']}\")\n",
    "            else:\n",
    "                print(f\"ğŸ’¡ ìµœì¢… íŒíŠ¸: {mission_data['hint_text_3']}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"ì•Œ ìˆ˜ ì—†ëŠ” ê²€ì¦ ë°©ë²•: {verification_method}\")\n",
    "        print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: 'image_text', 'text_text', 'vqa'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea9732",
   "metadata": {},
   "source": [
    "## 9. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63126fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 9. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ============================================================================\n",
    "\n",
    "def get_available_landmarks():\n",
    "    \"\"\"ì‚¬ìš© ê°€ëŠ¥í•œ ëœë“œë§ˆí¬ ëª©ë¡ ë°˜í™˜\"\"\"\n",
    "    return list(QUESTIONS.keys())\n",
    "\n",
    "def print_system_info():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"BLIP ê¸°ë°˜ ëœë“œë§ˆí¬ ì´ë¯¸ì§€ ê²€ì¦ ì‹œìŠ¤í…œ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\ní™˜ê²½: {'Google Colab' if IN_COLAB else 'ë¡œì»¬'}\")\n",
    "    print(f\"ì¥ì¹˜: {device}\")\n",
    "    print(f\"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}\")\n",
    "    print(f\"\\nì‚¬ìš© ê°€ëŠ¥í•œ ëœë“œë§ˆí¬:\")\n",
    "    for i, landmark in enumerate(get_available_landmarks(), 1):\n",
    "        print(f\"  {i}. {landmark}\")\n",
    "    print(\"\\nì‚¬ìš© ê°€ëŠ¥í•œ ê²€ì¦ ë°©ë²•:\")\n",
    "    print(\"  1. image_text: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (Ground Truth ìº¡ì…˜ í•„ìš”)\")\n",
    "    print(\"  2. text_text: í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦ (Ground Truth ìº¡ì…˜ í•„ìš”)\")\n",
    "    print(\"  3. vqa: VQA ìœ ì‚¬ë„ ê²€ì¦ (ì§ˆë¬¸ ì„¸íŠ¸ë§Œ í•„ìš”)\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"\\nì‚¬ìš© ì˜ˆì‹œ (Colab):\")\n",
    "        print(\"  run_mission_verification('image_text', 'ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ')\")\n",
    "        print(\"  run_mission_verification('vqa', 'í”¼ë…¸í‚¤ì˜¤')\")\n",
    "    else:\n",
    "        print(\"\\nì‚¬ìš© ì˜ˆì‹œ (ë¡œì»¬):\")\n",
    "        print(\"  run_mission_verification('image_text', 'ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ', image_path='test.jpg')\")\n",
    "        print(\"  run_mission_verification('vqa', 'í”¼ë…¸í‚¤ì˜¤', image_path='pinocchio.jpg')\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f645c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 1: ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸\n",
    "# ============================================================================\n",
    "\n",
    "def example_1_system_info():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì •ë³´ ë° ì‚¬ìš© ê°€ëŠ¥í•œ ëœë“œë§ˆí¬ í™•ì¸\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 1: ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥\n",
    "    print_system_info()\n",
    "    \n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ ëœë“œë§ˆí¬ ëª©ë¡\n",
    "    landmarks = get_available_landmarks()\n",
    "    print(f\"\\nì‚¬ìš© ê°€ëŠ¥í•œ ëœë“œë§ˆí¬: {landmarks}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 2: VQA ê²€ì¦ (ê°€ì¥ ê°„ë‹¨)\n",
    "# ============================================================================\n",
    "\n",
    "def example_2_vqa_verification():\n",
    "    \"\"\"VQA ê²€ì¦ - Ground Truth ìº¡ì…˜ ì—†ì´ ì§ˆë¬¸-ë‹µë³€ìœ¼ë¡œ ê²€ì¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 2: VQA ê²€ì¦\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Google Colab í™˜ê²½\n",
    "    # run_mission_verification('vqa', 'í”¼ë…¸í‚¤ì˜¤')\n",
    "    \n",
    "    # ë¡œì»¬ í™˜ê²½ (ì´ë¯¸ì§€ ê²½ë¡œ ì§€ì •)\n",
    "    run_mission_verification(\n",
    "        verification_method='vqa',\n",
    "        landmark_name='í”¼ë…¸í‚¤ì˜¤',\n",
    "        image_path='test_pinocchio.jpg'  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 3: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\n",
    "# ============================================================================\n",
    "\n",
    "def example_3_image_text_verification():\n",
    "    \"\"\"ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 3: ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    run_mission_verification(\n",
    "        verification_method='image_text',\n",
    "        landmark_name='ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ',\n",
    "        image_path='test_wisdom_forest.jpg'  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 4: í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\n",
    "# ============================================================================\n",
    "\n",
    "def example_4_text_text_verification():\n",
    "    \"\"\"í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 4: í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    run_mission_verification(\n",
    "        verification_method='text_text',\n",
    "        landmark_name='ë„¤ëª¨íƒ‘',\n",
    "        image_path='test_nemotop.jpg'  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 5: Ground Truth ìº¡ì…˜ ìƒì„±\n",
    "# ============================================================================\n",
    "\n",
    "def example_5_generate_captions():\n",
    "    \"\"\"í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ Ground Truth ìº¡ì…˜ ìƒì„±\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 5: Ground Truth ìº¡ì…˜ ìƒì„±\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    captions = generate_ground_truth_captions_from_folder(\n",
    "        landmark_name='í”¼ë…¸í‚¤ì˜¤',\n",
    "        data_dir='./data'  # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nìƒì„±ëœ ìº¡ì…˜ ìˆ˜: {len(captions)}\")\n",
    "    print(\"\\nìƒì„±ëœ ìº¡ì…˜ ëª©ë¡:\")\n",
    "    for i, caption in enumerate(captions[:5], 1):  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥\n",
    "        print(f\"  {i}. {caption}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 6: ë‹¨ì¼ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±\n",
    "# ============================================================================\n",
    "\n",
    "def example_6_single_image_caption():\n",
    "    \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ìº¡ì…˜ ìƒì„± (JSON í˜•ì‹ ì¶œë ¥)\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 6: ë‹¨ì¼ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    image = Image.open('test_image.jpg')  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½\n",
    "    \n",
    "    # ìº¡ì…˜ ìƒì„± (JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ë¨)\n",
    "    captions = generate_single_image_caption(image)\n",
    "    \n",
    "    print(f\"\\nìƒì„±ëœ ìº¡ì…˜: {captions}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 7: ì»¤ìŠ¤í…€ ë¯¸ì…˜ ë°ì´í„°\n",
    "# ============================================================================\n",
    "\n",
    "def example_7_custom_mission():\n",
    "    \"\"\"ì»¤ìŠ¤í…€ ë¯¸ì…˜ ë°ì´í„°ë¡œ ê²€ì¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 7: ì»¤ìŠ¤í…€ ë¯¸ì…˜ ë°ì´í„°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì»¤ìŠ¤í…€ ë¯¸ì…˜ ë°ì´í„°\n",
    "    custom_mission = {\n",
    "        \"id\": 99,\n",
    "        \"daily_keyword\": \"ë¬¸í™”\",\n",
    "        \"landmark_name\": \"í”¼ë…¸í‚¤ì˜¤\",\n",
    "        \"hint_text_1\": \"ì´ì•¼ê¸° ì† ì£¼ì¸ê³µì„ ì°¾ì•„ë³´ì„¸ìš”\",\n",
    "        \"hint_text_2\": \"ê¸´ ì½”ê°€ íŠ¹ì§•ì¸ ìºë¦­í„°ì…ë‹ˆë‹¤\",\n",
    "        \"hint_text_3\": \"ã…ã„´ã…‹ã…‡ (ì´ˆì„± íŒíŠ¸)\",\n",
    "        \"score_threshold_low\": 0.4,\n",
    "        \"score_threshold_high\": 0.75,\n",
    "        \"required_yes_ratio\": 0.7\n",
    "    }\n",
    "    \n",
    "    run_mission_verification(\n",
    "        verification_method='vqa',\n",
    "        landmark_name='í”¼ë…¸í‚¤ì˜¤',\n",
    "        mission_data=custom_mission,\n",
    "        image_path='test_pinocchio.jpg'\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 8: ì»¤ìŠ¤í…€ ë°ì´í„° ë””ë ‰í† ë¦¬\n",
    "# ============================================================================\n",
    "\n",
    "def example_8_custom_data_directory():\n",
    "    \"\"\"ì»¤ìŠ¤í…€ ë°ì´í„° ë””ë ‰í† ë¦¬ ì‚¬ìš©\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 8: ì»¤ìŠ¤í…€ ë°ì´í„° ë””ë ‰í† ë¦¬\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    run_mission_verification(\n",
    "        verification_method='vqa',\n",
    "        landmark_name='í”¼ë…¸í‚¤ì˜¤',\n",
    "        image_path='test_pinocchio.jpg',\n",
    "        data_dir='./my_custom_data'  # ì»¤ìŠ¤í…€ ë°ì´í„° ê²½ë¡œ\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 9: ê°œë³„ ê²€ì¦ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš©\n",
    "# ============================================================================\n",
    "\n",
    "def example_9_direct_verification():\n",
    "    \"\"\"ê²€ì¦ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 9: ê°œë³„ ê²€ì¦ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš©\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    user_image = Image.open('test_pinocchio.jpg')\n",
    "    \n",
    "    # VQA ê²€ì¦\n",
    "    yes_ratio, feedback = verify_vqa_similarity(\n",
    "        user_image=user_image,\n",
    "        landmark_name='í”¼ë…¸í‚¤ì˜¤',\n",
    "        required_yes_ratio=0.75\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nYES ë¹„ìœ¨: {yes_ratio}\")\n",
    "    print(f\"í”¼ë“œë°±: {feedback}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 10: ë°°ì¹˜ ì²˜ë¦¬\n",
    "# ============================================================================\n",
    "\n",
    "def example_10_batch_verification():\n",
    "    \"\"\"ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ê²€ì¦\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 10: ë°°ì¹˜ ì²˜ë¦¬\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    test_images = [\n",
    "        ('í”¼ë…¸í‚¤ì˜¤', 'test_pinocchio_1.jpg'),\n",
    "        ('í”¼ë…¸í‚¤ì˜¤', 'test_pinocchio_2.jpg'),\n",
    "        ('ë„¤ëª¨íƒ‘', 'test_nemotop_1.jpg'),\n",
    "        ('ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ', 'test_wisdom_1.jpg')\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for landmark_name, image_path in test_images:\n",
    "        print(f\"\\nê²€ì¦ ì¤‘: {image_path}\")\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "            yes_ratio, feedback = verify_vqa_similarity(\n",
    "                user_image=image,\n",
    "                landmark_name=landmark_name,\n",
    "                required_yes_ratio=0.75\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'landmark': landmark_name,\n",
    "                'image': image_path,\n",
    "                'yes_ratio': yes_ratio,\n",
    "                'success': yes_ratio >= 0.75 if yes_ratio else False\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"ì˜¤ë¥˜: {e}\")\n",
    "            results.append({\n",
    "                'landmark': landmark_name,\n",
    "                'image': image_path,\n",
    "                'error': str(e),\n",
    "                'success': False\n",
    "            })\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\" * 60)\n",
    "    for result in results:\n",
    "        status = \"âœ… ì„±ê³µ\" if result.get('success') else \"âŒ ì‹¤íŒ¨\"\n",
    "        print(f\"{status} | {result['landmark']} | {result['image']}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ì˜ˆì‹œ 11: ëª¨ë“  ê²€ì¦ ë°©ë²• ë¹„êµ\n",
    "# ============================================================================\n",
    "\n",
    "def example_11_compare_all_methods():\n",
    "    \"\"\"í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¡œ ì„¸ ê°€ì§€ ê²€ì¦ ë°©ë²• ë¹„êµ\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ì˜ˆì‹œ 11: ëª¨ë“  ê²€ì¦ ë°©ë²• ë¹„êµ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    image_path = 'test_pinocchio.jpg'\n",
    "    landmark_name = 'í”¼ë…¸í‚¤ì˜¤'\n",
    "    \n",
    "    # 1. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„\n",
    "    print(\"\\n1ï¸âƒ£ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"-\" * 40)\n",
    "    run_mission_verification('image_text', landmark_name, image_path=image_path)\n",
    "    \n",
    "    # 2. í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„\n",
    "    print(\"\\n2ï¸âƒ£ í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"-\" * 40)\n",
    "    run_mission_verification('text_text', landmark_name, image_path=image_path)\n",
    "    \n",
    "    # 3. VQA ê²€ì¦\n",
    "    print(\"\\n3ï¸âƒ£ VQA ê²€ì¦\")\n",
    "    print(\"-\" * 40)\n",
    "    run_mission_verification('vqa', landmark_name, image_path=image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc8e27",
   "metadata": {},
   "source": [
    "# BLIP ëœë“œë§ˆí¬ ê²€ì¦ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BLIP ëœë“œë§ˆí¬ ê²€ì¦ ì‹œìŠ¤í…œ - ì‚¬ìš© ì˜ˆì‹œ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nì‹¤í–‰í•  ì˜ˆì‹œë¥¼ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "    print(\"  1. ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸\")\n",
    "    print(\"  2. VQA ê²€ì¦\")\n",
    "    print(\"  3. ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"  4. í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê²€ì¦\")\n",
    "    print(\"  5. Ground Truth ìº¡ì…˜ ìƒì„±\")\n",
    "    print(\"  6. ë‹¨ì¼ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±\")\n",
    "    print(\"  7. ì»¤ìŠ¤í…€ ë¯¸ì…˜ ë°ì´í„°\")\n",
    "    print(\"  8. ì»¤ìŠ¤í…€ ë°ì´í„° ë””ë ‰í† ë¦¬\")\n",
    "    print(\"  9. ê°œë³„ ê²€ì¦ í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš©\")\n",
    "    print(\" 10. ë°°ì¹˜ ì²˜ë¦¬\")\n",
    "    print(\" 11. ëª¨ë“  ê²€ì¦ ë°©ë²• ë¹„êµ\")\n",
    "    print(\" 0. ëª¨ë‘ ì‹¤í–‰\")\n",
    "    \n",
    "    choice = input(\"\\nì„ íƒ (0-11): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        example_1_system_info()\n",
    "    elif choice == \"2\":\n",
    "        example_2_vqa_verification()\n",
    "    elif choice == \"3\":\n",
    "        example_3_image_text_verification()\n",
    "    elif choice == \"4\":\n",
    "        example_4_text_text_verification()\n",
    "    elif choice == \"5\":\n",
    "        example_5_generate_captions()\n",
    "    elif choice == \"6\":\n",
    "        example_6_single_image_caption()\n",
    "    elif choice == \"7\":\n",
    "        example_7_custom_mission()\n",
    "    elif choice == \"8\":\n",
    "        example_8_custom_data_directory()\n",
    "    elif choice == \"9\":\n",
    "        example_9_direct_verification()\n",
    "    elif choice == \"10\":\n",
    "        example_10_batch_verification()\n",
    "    elif choice == \"11\":\n",
    "        example_11_compare_all_methods()\n",
    "    elif choice == \"0\":\n",
    "        # ëª¨ë‘ ì‹¤í–‰ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)\n",
    "        example_1_system_info()\n",
    "        # ë‚˜ë¨¸ì§€ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ê°€ í•„ìš”í•˜ë¯€ë¡œ ê±´ë„ˆëœ€\n",
    "        print(\"\\në‚˜ë¨¸ì§€ ì˜ˆì‹œëŠ” ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
