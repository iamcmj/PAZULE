# models/llm_hint_generator.py

import os
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# GPT ëª¨ë¸ ì„¤ì •
MODEL_NAME = "gpt-4o-mini"


def generate_blip_hint(answer, blip_failed_questions=None):
    """
    BLIP VQAì—ì„œ í‹€ë¦° ì§ˆë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ìƒì  íŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        answer (str): ì •ë‹µ ëœë“œë§ˆí¬ ì´ë¦„ (ì˜ˆ: "ë„¤ëª¨íƒ‘")
        blip_failed_questions (list): í‹€ë¦° ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
            [{"question": str, "expected_answer": str, "model_answer": str}, ...]

    Returns:
        str: LLMì´ ìƒì„±í•œ íŒíŠ¸ ë©”ì‹œì§€

    Raises:
        ValueError: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ë•Œ
    """

    # API í‚¤ í™•ì¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒíŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return f"ë‹¤ì‹œ í•œ ë²ˆ ì£¼ë³€ì„ ë‘˜ëŸ¬ë³´ì„¸ìš”. '{answer}'ì™€ ê´€ë ¨ëœ íŠ¹ë³„í•œ ì¥ì†Œê°€ ìˆì„ ê±°ì˜ˆìš”! ğŸ’¡"

    if blip_failed_questions is None:
        blip_failed_questions = []

    # í‹€ë¦° ì§ˆë¬¸ ì •ë³´ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…
    failed_info = ""
    if blip_failed_questions:
        failed_info = "\nì‚¬ìš©ì ì‚¬ì§„ì—ì„œ ë¶€ì¡±í•œ íŠ¹ì§• (BLIP VQA ê²°ê³¼):\n"
        for i, item in enumerate(blip_failed_questions, 1):
            question = item.get("question", "N/A")
            expected_answer = item.get("expected_answer", "N/A")
            model_answer = item.get("model_answer", "N/A")
            failed_info += f'  {i}. ì§ˆë¬¸: "{question}"\n'
            failed_info += f"     - ëª¨ë¸ ë‹µë³€: '{model_answer}', ê¸°ëŒ€ ë‹µë³€: '{expected_answer}'\n"
    else:
        failed_info = "\nì‚¬ìš©ì ì‚¬ì§„ì—ì„œ ë¶€ì¡±í•œ íŠ¹ì§•: (ì •ë³´ ì—†ìŒ)\n"

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ íŒŒì£¼ ì¶œíŒë‹¨ì§€ ë³´ë¬¼ì°¾ê¸° ê²Œì„ì˜ íŒíŠ¸ ì œê³µìì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì´¬ì˜í•œ ì‚¬ì§„ì´ ì •ë‹µ ëœë“œë§ˆí¬ê°€ ì•„ë‹ ë•Œ, ì¶”ìƒì ì´ê³  ì°½ì˜ì ì¸ íŒíŠ¸ë¥¼ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

### íŒíŠ¸ ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ì •ë‹µ ëœë“œë§ˆí¬ ì´ë¦„ì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
2. 2-3ë¬¸ì¥ì˜ ì§§ê³  ê°ì„±ì ì¸ íŒíŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
3. ì€ìœ ì ì´ê³  ì‹œì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
4. BLIP VQA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ì§„ì— ì—†ëŠ” íŠ¹ì§•ì„ ê°„ì ‘ì ìœ¼ë¡œ ì•”ì‹œí•˜ê±°ë‚˜, ì˜ëª» ì¸ì‹ëœ íŠ¹ì§•ì„ ì •ë‹µê³¼ ëŒ€ì¡°í•˜ì„¸ìš”.
5. ì‚¬ìš©ìê°€ ë‹¤ì‹œ ë„ì „í•˜ê³  ì‹¶ì€ ë§ˆìŒì´ ë“¤ë„ë¡ ê²©ë ¤í•˜ì„¸ìš”.
6. í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
7. ë„ˆë¬´ ë“¤ëœ¨ê±°ë‚˜ ì¥ë‚œìŠ¤ëŸ¬ìš´ í†¤ì€ í”¼í•´ì£¼ì„¸ìš”.

### íŒíŠ¸ ì‘ì„± ì˜ˆì‹œ:

**ì˜ˆì‹œ 1: ì •ë‹µì˜ íŠ¹ì§•ì´ ì‚¬ì§„ì— ì—†ì„ ë•Œ (ê¸°ëŒ€ ë‹µë³€ 'yes', ëª¨ë¸ ë‹µë³€ 'no')**
- **ì •ë‹µ:** í”¼ë…¸í‚¤ì˜¤
- **ì…ë ¥ ì •ë³´:**
    - ì§ˆë¬¸: "Does the statue have a particularly long nose?"
    - ëª¨ë¸ ë‹µë³€: 'no', ê¸°ëŒ€ ë‹µë³€: 'yes'
- **ì¢‹ì€ íŒíŠ¸:** "ì§„ì‹¤ì˜ ë¬´ê²Œë¥¼ ì½” ëìœ¼ë¡œ ì¦ëª…í•˜ëŠ” ì¹œêµ¬ë¥¼ ì°¾ì•„ë³´ì„¸ìš”. ë•Œë¡œëŠ” ì‘ì€ ê±°ì§“ë§ì´ ê°€ì¥ í° íŠ¹ì§•ì´ ë˜ê¸°ë„ í•œë‹µë‹ˆë‹¤."
- **ë‚˜ìœ íŒíŠ¸:** "ì½”ê°€ ê¸´ ì¸í˜•ì„ ì°¾ì•„ë³´ì„¸ìš”." (ë„ˆë¬´ ì§ì ‘ì ì„)

**ì˜ˆì‹œ 2: ì •ë‹µì´ ì•„ë‹Œ ë‹¤ë¥¸ ëŒ€ìƒì„ ì°ì—ˆì„ ë•Œ (ê¸°ëŒ€ ë‹µë³€ 'no', ëª¨ë¸ ë‹µë³€ 'yes')**
- **ì •ë‹µ:** ë„¤ëª¨íƒ‘
- **ì…ë ¥ ì •ë³´:**
    - ì§ˆë¬¸: "Are there any books in the photo?"
    - ëª¨ë¸ ë‹µë³€: 'yes', ê¸°ëŒ€ ë‹µë³€: 'no' (ì‚¬ìš©ìê°€ ì±…ì´ ë§ì€ 'ì§€í˜œì˜ ìˆ²'ì„ ì°ì—ˆë‹¤ê³  ê°€ì •)
- **ì¢‹ì€ íŒíŠ¸:** "ì´ì•¼ê¸°ê°€ ì ë“  ê³ ìš”í•œ ìˆ²ë„ ì•„ë¦„ë‹µì§€ë§Œ, ìš°ë¦¬ê°€ ì°¾ëŠ” ë³´ë¬¼ì€ í•˜ëŠ˜ì„ í–¥í•´ ì§€í˜œë¥¼ ì¸µì¸µì´ ìŒ“ì•„ ì˜¬ë¦° ê³³ì— ìˆ¨ê²¨ì ¸ ìˆì–´ìš”."
- **ë‚˜ìœ íŒíŠ¸:** "ì±…ì´ ì•„ë‹ˆë¼ íƒ‘ì„ ì°ì–´ì•¼ í•´ìš”." (ë„ˆë¬´ ì§ì ‘ì ì„)

### ì£¼ì˜ì‚¬í•­:
- ì˜ëª»ëœ íŠ¹ì§•(ëª¨ë¸ì´ 'yes'ë¼ê³  í–ˆì§€ë§Œ 'no'ê°€ ê¸°ëŒ€ë¨)ì€ ì˜¤ë‹µì„ì„ ëª…í™•íˆ í•˜ì„¸ìš”.
- ë¶€ì¡±í•œ íŠ¹ì§•(ëª¨ë¸ì´ 'no'ë¼ê³  í–ˆì§€ë§Œ 'yes'ê°€ ê¸°ëŒ€ë¨)ì€ ê°„ì ‘ì ìœ¼ë¡œ ì•”ì‹œí•˜ì„¸ìš”.
"""

    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
    user_prompt = f"""ì •ë‹µ ëœë“œë§ˆí¬: {answer}
{failed_info}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì •ë‹µì— ë” ê°€ê¹Œì´ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ì¶”ìƒì ì´ê³  ì°½ì˜ì ì¸ íŒíŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

    print(f"âœ… LLM íŒíŠ¸ ìƒì„± ì‹œë„ (API í‚¤ ì„¤ì •ë¨, ê¸¸ì´: {len(api_key)}ì)")

    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,  # ì°½ì˜ì ì¸ íŒíŠ¸ë¥¼ ìœ„í•´ ë†’ì€ temperature ì„¤ì •
            max_tokens=200
        )

        hint = response.choices[0].message.content.strip()
        print("âœ… LLM íŒíŠ¸ ìƒì„± ì„±ê³µ")
        return hint

    except Exception as e:
        print(f"âŒ Error generating hint with GPT: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ íŒíŠ¸ ë°˜í™˜
        return f"ë‹¤ì‹œ í•œ ë²ˆ ì£¼ë³€ì„ ë‘˜ëŸ¬ë³´ì„¸ìš”. '{answer}'ì™€ ê´€ë ¨ëœ íŠ¹ë³„í•œ ì¥ì†Œê°€ ìˆì„ ê±°ì˜ˆìš”! ğŸ’¡"


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
    print("=== LLM Hint Generator í…ŒìŠ¤íŠ¸ ===\n")

    # ì˜ˆì‹œ 1: í”¼ë…¸í‚¤ì˜¤
    print("--- ì˜ˆì‹œ 1: í”¼ë…¸í‚¤ì˜¤ ---")
    test_answer_1 = "í”¼ë…¸í‚¤ì˜¤"
    test_blip_questions_1 = [
        {
            "question": "Does the statue have a particularly long nose?",
            "model_answer": "no",
            "expected_answer": "yes"
        },
        {
            "question": "Is the statue wearing green-colored clothes?",
            "model_answer": "no",
            "expected_answer": "yes"
        },
        {
            "question": "Is the object the statue is holding a book?",
            "model_answer": "yes",
            "expected_answer": "no"
        }
    ]
    
    print(f"ì •ë‹µ: {test_answer_1}")
    print(f"BLIP ì‹¤íŒ¨ ì§ˆë¬¸ ìˆ˜: {len(test_blip_questions_1)}")
    
    hint_1 = generate_blip_hint(test_answer_1, test_blip_questions_1)
    print("\nìƒì„±ëœ íŒíŠ¸:")
    print(hint_1)
    print("\n" + "="*50 + "\n")
    
    # ì˜ˆì‹œ 2: ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ
    print("--- ì˜ˆì‹œ 2: ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ ---")
    test_answer_2 = "ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ"
    test_blip_questions_2 = [
        {"question": "Is the sculpture made of glass?", "model_answer": "yes", "expected_answer": "no"},
        {"question": "Does the sculpture have a tail?", "model_answer": "yes", "expected_answer": "no"},
        {"question": "Is the sculpture standing up?", "model_answer": "yes", "expected_answer": "no"},
        {"question": "Is the sculpture holding an object to its eyes?", "model_answer": "no", "expected_answer": "yes"},
        {"question": "Is the sculpture in a sitting position?", "model_answer": "no", "expected_answer": "yes"}
    ]

    print(f"ì •ë‹µ: {test_answer_2}")
    print(f"BLIP ì‹¤íŒ¨ ì§ˆë¬¸ ìˆ˜: {len(test_blip_questions_2)}")

    hint_2 = generate_blip_hint(test_answer_2, test_blip_questions_2)
    print("\nìƒì„±ëœ íŒíŠ¸:")
    print(hint_2)
    print("\n" + "="*50 + "\n")

