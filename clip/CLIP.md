# 이미지 분위기 분석 파이프라인 (CLIP with BLIP)

먼저 **BLIP (VQA)** 모델을 사용하여 각 이미지에 대한 설명 키워드(분위기)를 자동으로 생성합니다. 그다음, **CLIP** 모델을 사용하여 이 키워드들을 프롬프트로 변환하고, 각 랜드마크 카테고리에서 어떤 분위기가 가장 적합한지 랭킹을 매기고 분류합니다.

## 사용 모델

* **VQA (질의응답) 모델:** `Salesforce/blip-vqa-base`
* **이미지-텍스트 유사도 모델:** `openai/clip-vit-base-patch32`

## 프로젝트 워크플로우

### 1. 1단계: 분위기 키워드 생성 (BLIP-VQA 활용)

1.  **데이터 로드:** 특정 경로에서 랜드마크별(예: "네모탑", "웅진역사관") 이미지 파일들을 로드합니다.
2.  **질문 생성:** 데이터셋의 **모든** 이미지에 대해 BLIP-VQA 모델에게 동일한 질문을 던집니다: `"What's the atmosphere of this place like?"` (이 장소의 분위기는 어떤가요?)
3.  **답변 수집:** 모델이 생성한 답변(예: "calm", "peaceful", "urban", "gloomy")을 수집합니다.
4.  **키워드 요약:** `Counter`를 사용하여 각 랜드마크 카테고리별로 가장 자주 등장한 '분위기' 키워드를 집계합니다.

### 2. 2단계: 분위기 분류 및 랭킹 (CLIP 활용)

1.  **프롬프트 생성:** 1단계에서 생성된 키워드(예: "calm")를 CLIP 모델이 이해할 수 있는 완전한 문장 프롬프트(예: `"A photo that conveys a calm mood."`)로 변환합니다.
2.  **유사도 계산:** 특정 랜드마크(예: "네모탑")의 모든 이미지와 해당 랜드마크에서 생성된 모든 분위기 프롬프트를 CLIP 모델에 입력합니다.
3.  **배치 분석:** 모델은 각 이미지가 어떤 분위기 프롬프트와 가장 높은 코사인 유사도를 갖는지 계산합니다.
4.  **결과 분석 및 집계:** 노트북은 두 가지 방식으로 최종 결과를 분석합니다.
    * **Top-1 분석:** 각 이미지에 대해 **가장 높은 확률**을 가진 단일 분위기 프롬프트를 선택합니다. 이후 어떤 분위기가 'Best'로 가장 많이 선택되었는지 집계합니다.
    * **Top-5 분석:** 각 이미지에 대해 **상위 5개**의 일치하는 분위기 프롬프트를 선택합니다. 이후 Top-5 목록에 포함된 모든 분위기를 집계하여 더 풍부하고 미묘한 "분위기 프로필"을 도출합니다.


### 결론

BLIP으로 atmosphere, mood에 대한 label을 뽑아낸 다음 해당 label을 통해 clip과 이미지의 유사도를 비교해 보았음
Top-5 정도로 통계를 내보았을 때 BLIP에서 나온 label과 약간? 유사한 분포를 가지는 것을 확인할 수 있었음
Top-1으로 했을 때는 BLIP에서의 결과랑 아예 다름