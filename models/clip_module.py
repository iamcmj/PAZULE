# clip_module.py
import re, torch, os, sys
from PIL import Image
# clip_module ë‹¨ë…ìœ¼ë¡œ ëŒë¦¬ê¸° ìœ„í•´ì„œ ë„£ì€ ê²ƒ, ë‚˜ì¤‘ì— ë¹¼ì•¼ ë¨
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.clip_loader import clip_model, clip_processor, device
from config.keyword import keyword_mapping, kw_strong, kw_middle, kw_weak, feedback_guide


def make_label_pairs(keyword_mapping):
    label_pairs = []
    for _, value in keyword_mapping.items():
        for v in value:
            label_pairs.append(v)
    return label_pairs

def make_prompts_from_keywords(keywords, templates=None):
    if templates is None:
        templates = [
            "A photo that conveys a {} mood.",
            "An image evoking a feeling of {}.",
            "A picture that feels {}.",
            # "A scene with a {} atmosphere.", # í•„ìš”ì‹œ ì¶”ê°€í•  ê²ƒ
            # "A photo expressing {} emotions."
        ]

    prompts = []
    for kw in keywords:
        tmp = []
        for t in templates:
            tmp.append(t.format(kw))
        prompts.append(' '.join(tmp))

    return prompts

def analyze_mood(image, keywords, top):
    prompts = make_prompts_from_keywords(keywords)
    inputs = clip_processor(text=prompts, images=image, return_tensors="pt", padding=True).to(device)
    outputs = clip_model(**inputs)

    logits_per_image = outputs.logits_per_image
    probs = logits_per_image.softmax(dim=1)

    topk = torch.topk(probs, k=top)
    top_keywords = []
    scores = []

    for idx, score in zip(topk.indices[0].tolist(), topk.values[0].tolist()):
        match = re.search(r"conveys a (.+?) mood", prompts[idx])
        kw = match.group(1)
        top_keywords.append(kw)
        scores.append(f"{score*100:.1f}")

    return top_keywords, scores

def find_mood(target):
    for key, values in keyword_mapping.items():
        if target in values:
            return key

def check_with_clip(image, kw):
    print(f"ì˜¤ëŠ˜ì˜ ë¯¸ì…˜: {kw} ë¶„ìœ„ê¸°, ê°ì„±ì„ ì§€ë‹ˆê³  ìˆëŠ” ê³³ì„ ì§ì ‘ ì°ì–´ë³´ì„¸ìš”!")
    label_pairs = make_label_pairs(keyword_mapping)
    
    if kw in kw_strong:
        guide = feedback_guide
        top_keywords, scores = analyze_mood(image, label_pairs, 5)

        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(guide[find_mood(key)]["keywords"][key])

        if top_mood[0] == kw and top_mood[1] == kw:
            result = f"ì™„ë²½í•©ë‹ˆë‹¤!!ğŸ¥³ {kw} ëŠë‚Œì„ ì•„ì£¼ ì˜ ë‹´ìœ¼ì…¨ì–´ìš”!"
        elif top_mood[0] == kw or sum(k == kw for k in top_mood) >= 3:
            result = f"í›Œë¥­í•©ë‹ˆë‹¤â˜ºï¸ {kw} ëŠë‚Œì´ ì˜ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤!"
        elif kw in top_mood:
            result = f"ì¡°ê¸ˆë§Œ ë” {kw} ëŠë‚Œì„ ë‹´ì•„ ë³´ì„¸ìš”ğŸ™‚ í˜„ì¬ëŠ” {top_mood[0]} ëŠë‚Œì´ ë” ê°•í•©ë‹ˆë‹¤!\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ê°•í•˜ê²Œ ì¸ì‹í•œ í‚¤ì›Œë“œ 2ê°œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
                if i == 1:
                    break
        else:
            result = f"ì•„ì‰½ìŠµë‹ˆë‹¤...ğŸ¥² {kw} ê°ì„±ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤ ã…œã…œ\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ì¸ì‹í•œ í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
            result += f"\nğŸ’¡ {guide[kw]['desc']}\n\n"
            result += "ğŸ“· ì´ëŸ¬í•œ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”:\n"
            for eng, kor in guide[kw]["keywords"].items():
                result += f" - {kor}\n"

        print(result)

    elif kw in kw_middle:
        guide = feedback_guide
        top_keywords, scores = analyze_mood(image, label_pairs, 7)

        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(guide[find_mood(key)]["keywords"][key])

        if top_mood[0] == kw or sum(k == kw for k in top_mood[:5]) >= 2:
            result = f"ì™„ë²½í•©ë‹ˆë‹¤!!ğŸ¥³ {kw} ëŠë‚Œì„ ì•„ì£¼ ì˜ ë‹´ìœ¼ì…¨ì–´ìš”!"
        elif sum(k == kw for k in top_mood) >= 2:
            result = f"í›Œë¥­í•©ë‹ˆë‹¤â˜ºï¸ {kw} ëŠë‚Œì´ ì˜ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤!"
        elif kw in top_mood:
            result = f"ì¡°ê¸ˆë§Œ ë” {kw} ëŠë‚Œì„ ë‹´ì•„ ë³´ì„¸ìš”ğŸ™‚ í˜„ì¬ëŠ” {top_mood[0]} ëŠë‚Œì´ ë” ê°•í•©ë‹ˆë‹¤!\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ê°•í•˜ê²Œ ì¸ì‹í•œ í‚¤ì›Œë“œ 2ê°œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
                if i == 1:
                    break
        else:
            result = f"ì•„ì‰½ìŠµë‹ˆë‹¤...ğŸ¥² {kw} ê°ì„±ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤ ã…œã…œ\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ì¸ì‹í•œ í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
            result += f"\nğŸ’¡ {guide[kw]['desc']}\n\n"
            result += "ğŸ“· ì´ëŸ¬í•œ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”:\n"
            for eng, kor in guide[kw]["keywords"].items():
                result += f" - {kor}\n"

        print(result)

    else:
        guide = feedback_guide
        top_keywords, scores = analyze_mood(image, label_pairs, 9)

        top_mood = []
        top_mood_specific = []

        for key in top_keywords:
            top_mood.append(find_mood(key))
            top_mood_specific.append(guide[find_mood(key)]["keywords"][key])

        if top_mood[0] == kw or sum(k == kw for k in top_mood[:7]) >= 2:
            result = f"ì™„ë²½í•©ë‹ˆë‹¤!!ğŸ¥³ {kw} ëŠë‚Œì„ ì•„ì£¼ ì˜ ë‹´ìœ¼ì…¨ì–´ìš”!"
        elif kw in top_mood[:7]:
            result = f"í›Œë¥­í•©ë‹ˆë‹¤â˜ºï¸ {kw} ëŠë‚Œì´ ì˜ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤!"
        elif kw in top_mood:
            result = f"ì¡°ê¸ˆë§Œ ë” {kw} ëŠë‚Œì„ ë‹´ì•„ ë³´ì„¸ìš”ğŸ™‚ í˜„ì¬ëŠ” {top_mood[0]} ëŠë‚Œì´ ë” ê°•í•©ë‹ˆë‹¤!\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ê°•í•˜ê²Œ ì¸ì‹í•œ í‚¤ì›Œë“œ 2ê°œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
                if i == 1:
                    break
        else:
            result = f"ì•„ì‰½ìŠµë‹ˆë‹¤...ğŸ¥² {kw} ê°ì„±ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤ ã…œã…œ\n"
            result += f"í˜„ì¬ ì´ ì‚¬ì§„ìœ¼ë¡œë¶€í„° ì¸ì‹í•œ í‚¤ì›Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤!\n"
            for i, m in enumerate(top_mood_specific):
                result += f"{i+1}. {m}({top_mood[i]})\n"
            result += f"\nğŸ’¡ {guide[kw]['desc']}\n\n"
            result += "ğŸ“· ì´ëŸ¬í•œ í‚¤ì›Œë“œë¥¼ ì°¸ê³ í•´ë³´ì„¸ìš”:\n"
            for eng, kor in guide[kw]["keywords"].items():
                result += f" - {kor}\n"
        print(result)
        
        
if __name__ == "__main__":
    # ì˜ˆì‹œ ì‹¤í–‰
    # ëŒë ¤ë³´ê³  ì‹¶ìœ¼ë©´ python model/clip_module.py
    kw = "í™œê¸°ì°¬"
    image_path = "../data/ì§€í˜œì˜ìˆ² ì¡°ê°ìƒ/IMG_9802.jpg"
    image = Image.open(image_path).convert("RGB")

    check_with_clip(image, kw)